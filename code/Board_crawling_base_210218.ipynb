{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EFePo3-Bqyws"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crawler(x_code, x_page):\n",
    "    # start = time.time()\n",
    "    df = pd.DataFrame(columns = [\n",
    "    'date',\n",
    "    'title',\n",
    "    'content',\n",
    "    'click',\n",
    "    'good',\n",
    "    'bad'\n",
    "    ])\n",
    "\n",
    "    if page == 'all':\n",
    "        # 마지막 페이지\n",
    "        url = \"https://finance.naver.com/item/board.nhn?code={}&page={}\".format(x_code, 1)\n",
    "        html = requests.get(url, headers = headers).text\n",
    "        soup = bs(html, 'html.parser')\n",
    "        last_page = soup.select('#content > div.section.inner_sub > table:nth-child(3) > tbody > tr > td:nth-child(2) > table > tbody > tr > td.pgRR ')[0]\n",
    "        last_page = last_page.find('a')\n",
    "        last_page = last_page.attrs['href'][33:]\n",
    "        last_page = int(last_page)\n",
    "        # print(last_page)\n",
    "        \n",
    "        for p in range(1, last_page+1):\n",
    "            url = \"https://finance.naver.com/item/board.nhn?code={}&page={}\".format(x_code, p)\n",
    "            html = requests.get(url, headers = headers).text\n",
    "            soup = bs(html, 'html.parser')\n",
    "            base = soup.select('#content > div.section.inner_sub > table.type2 > tbody')[0]\n",
    "            \n",
    "            for i in range(3, 26):\n",
    "                    # 5칸마다 있는 줄에 해당할 경우 contunue\n",
    "                try:\n",
    "                    if i == 8 or i == 14 or i == 20:\n",
    "                        continue\n",
    "\n",
    "                    date = base.select('tr:nth-child({}) > td:nth-child(1) > span'.format(i))[0].text\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "                title = base.select('tr:nth-child({}) > td.title > a'.format(i))[0].text\n",
    "                click = base.select('tr:nth-child({}) > td:nth-child(4) > span'.format(i))[0].text\n",
    "                good = base.select('tr:nth-child({}) > td:nth-child(5) > strong'.format(i))[0].text\n",
    "                bad = base.select('tr:nth-child({}) > td:nth-child(6) > strong'.format(i))[0].text\n",
    "\n",
    "                # href 얻기\n",
    "                href = base.select('tr:nth-child({}) > td.title'.format(i))[0]\n",
    "                href = href.find('a')\n",
    "                href = href.attrs['href']\n",
    "\n",
    "                # 본문 내용 얻기\n",
    "                content_url = ('https://finance.naver.com'+ href)\n",
    "                content_html = requests.get(content_url, headers = headers).text\n",
    "                content_soup = bs(content_html, 'html.parser')\n",
    "                content = content_soup.find(\"div\", \"view_se\").text\n",
    "\n",
    "                # df에 저장\n",
    "                result = {\n",
    "                    'date':date,\n",
    "                    'title':title,\n",
    "                    'content':content,\n",
    "                    'click':click,\n",
    "                    'good':good,\n",
    "                    'bad':bad\n",
    "                    }\n",
    "                df = df.append(result, ignore_index = True)\n",
    "                #end = time.time()\n",
    "                #print(\"경과 시간: {}\".format(end - start))\n",
    "    else:\n",
    "        for p in range(1, x_page+1):\n",
    "            url = \"https://finance.naver.com/item/board.nhn?code={}&page={}\".format(x_code, p)\n",
    "            html = requests.get(url, headers = headers).text\n",
    "            soup = bs(html, 'html.parser')\n",
    "            base = soup.select('#content > div.section.inner_sub > table.type2 > tbody')[0]\n",
    "\n",
    "            for i in range(3, 26):\n",
    "                # 5칸마다 있는 줄에 해당할 경우 contunue\n",
    "                try:\n",
    "                    if i == 8 or i == 14 or i == 20:\n",
    "                        continue\n",
    "\n",
    "                    date = base.select('tr:nth-child({}) > td:nth-child(1) > span'.format(i))[0].text\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "                title = base.select('tr:nth-child({}) > td.title > a'.format(i))[0].text\n",
    "                click = base.select('tr:nth-child({}) > td:nth-child(4) > span'.format(i))[0].text\n",
    "                good = base.select('tr:nth-child({}) > td:nth-child(5) > strong'.format(i))[0].text\n",
    "                bad = base.select('tr:nth-child({}) > td:nth-child(6) > strong'.format(i))[0].text\n",
    "\n",
    "                # href 얻기\n",
    "                href = base.select('tr:nth-child({}) > td.title'.format(i))[0]\n",
    "                href = href.find('a')\n",
    "                href = href.attrs['href']\n",
    "\n",
    "                # 본문 내용 얻기\n",
    "                content_url = ('https://finance.naver.com'+ href)\n",
    "                content_html = requests.get(content_url, headers = headers).text\n",
    "                content_soup = bs(content_html, 'html.parser')\n",
    "                content = content_soup.find(\"div\", \"view_se\").text\n",
    "\n",
    "                # df에 저장\n",
    "                result = {\n",
    "                    'date':date,\n",
    "                    'title':title,\n",
    "                    'content':content,\n",
    "                    'click':click,\n",
    "                    'good':good,\n",
    "                    'bad':bad\n",
    "                    }\n",
    "                df = df.append(result, ignore_index = True)\n",
    "            #end = time.time()\n",
    "            #print(\"경과 시간: {}\".format(end - start))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "code = '094170'\n",
    "page = 10# 마지막 페이지까지 하고 싶으면 'all'\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>click</th>\n",
       "      <th>good</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.02.18 17:17</td>\n",
       "      <td>이거 사고 싶은데 내일 떨어질확률이 높을...\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t</td>\n",
       "      <td>제가 생각없다고 생각하시는 어른분들은 제가 만으로 14살인거 생각해주세요</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021.02.18 15:25</td>\n",
       "      <td>10300에 대기\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t</td>\n",
       "      <td>빨리 던져줘</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021.02.18 13:25</td>\n",
       "      <td>C8\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t</td>\n",
       "      <td>또   또   짜증나게  하는구만!\\rㅎ ㅎ ㅎ</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.02.18 09:20</td>\n",
       "      <td>그냥 개미털기임\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t</td>\n",
       "      <td>천천히보유\\r 올해 기대주</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021.02.18 11:19</td>\n",
       "      <td>그냥 개미털기임\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t</td>\n",
       "      <td>10,500까지는 기다려야지.. 지금 달라들면 털려유\\r밑에다 받쳐놓고 대차물량 던...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2020.12.27 08:51</td>\n",
       "      <td>음...... 올해는 회사 보너스 주시려...\\n\\t\\t\\t\\t[1]\\n</td>\n",
       "      <td>열심히 일 잘하고 있는데.\\r 보너스는 주시겠죠?\\r 회사 주가도 많이 올라갔는데....</td>\n",
       "      <td>541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2020.12.25 23:19</td>\n",
       "      <td>(倭색풍의 가녀린 간드러진)《기름기 쩐 ...\\n\\t\\t\\t\\t[1]\\n</td>\n",
       "      <td>&lt;들어가기 전에&gt; (가필본) \\r 0 지저분한 사생활 여부 등에 관해서는 여기서는...</td>\n",
       "      <td>523</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2020.12.25 09:15</td>\n",
       "      <td>4700원대에 들어와서\\n\\t\\t\\t\\t[1]\\n</td>\n",
       "      <td>7천원에 팔고 갔는데 12000원 되어있?ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ와~\\r만원아나텍...</td>\n",
       "      <td>767</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2020.12.25 00:09</td>\n",
       "      <td>변종\\n\\t\\t\\t\\t[1]\\n</td>\n",
       "      <td>https://youtu.be/KgM5pv1JHjc</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2020.12.24 20:13</td>\n",
       "      <td>년내에\\n\\t\\t\\t\\t[6]\\n</td>\n",
       "      <td>년내에\\r최고가 간다\\r18층</td>\n",
       "      <td>822</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                          title  \\\n",
       "0    2021.02.18 17:17  이거 사고 싶은데 내일 떨어질확률이 높을...\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t   \n",
       "1    2021.02.18 15:25                  10300에 대기\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t   \n",
       "2    2021.02.18 13:25                         C8\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t   \n",
       "3    2021.02.18 09:20                   그냥 개미털기임\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t   \n",
       "4    2021.02.18 11:19                   그냥 개미털기임\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t   \n",
       "..                ...                                            ...   \n",
       "195  2020.12.27 08:51       음...... 올해는 회사 보너스 주시려...\\n\\t\\t\\t\\t[1]\\n   \n",
       "196  2020.12.25 23:19       (倭색풍의 가녀린 간드러진)《기름기 쩐 ...\\n\\t\\t\\t\\t[1]\\n   \n",
       "197  2020.12.25 09:15                    4700원대에 들어와서\\n\\t\\t\\t\\t[1]\\n   \n",
       "198  2020.12.25 00:09                              변종\\n\\t\\t\\t\\t[1]\\n   \n",
       "199  2020.12.24 20:13                             년내에\\n\\t\\t\\t\\t[6]\\n   \n",
       "\n",
       "                                               content click good bad  \n",
       "0             제가 생각없다고 생각하시는 어른분들은 제가 만으로 14살인거 생각해주세요    10    0   0  \n",
       "1                                               빨리 던져줘    41    0   0  \n",
       "2                          또   또   짜증나게  하는구만!\\rㅎ ㅎ ㅎ     87    0   0  \n",
       "3                                       천천히보유\\r 올해 기대주   133    0   0  \n",
       "4    10,500까지는 기다려야지.. 지금 달라들면 털려유\\r밑에다 받쳐놓고 대차물량 던...    82    0   0  \n",
       "..                                                 ...   ...  ...  ..  \n",
       "195  열심히 일 잘하고 있는데.\\r 보너스는 주시겠죠?\\r 회사 주가도 많이 올라갔는데....   541    1   1  \n",
       "196   <들어가기 전에> (가필본) \\r 0 지저분한 사생활 여부 등에 관해서는 여기서는...   523    2   3  \n",
       "197  7천원에 팔고 갔는데 12000원 되어있?ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ와~\\r만원아나텍...   767    4   1  \n",
       "198                       https://youtu.be/KgM5pv1JHjc   494    0   0  \n",
       "199                                   년내에\\r최고가 간다\\r18층   822    1   2  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crawling\n",
    "df = Crawler(code, page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "df.to_excel('{}_result.xlsx'.format(code))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "investor_crawling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
